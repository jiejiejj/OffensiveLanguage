# -*- coding: utf-8 -*-
"""Glacian-English

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Hnw4suDP5CiiACacou2vC10xbYsMfVDy
"""
import gc
import os
import numpy as np
import torch
import torch.nn as nn
import torch.utils.data as Data
from tqdm import tqdm
from sklearn.metrics import *
from transformers import *
from utils import *
import argparse
from datetime import timedelta
import wandb
from collections import defaultdict
try:
    from apex import amp
    USE_AMP = False #True
except ImportError:
    USE_AMP = False
    print('Warning: Apex not installed.')

lang2id = {'ar': 1, 'da': 2, 'de': 3, 'en': 4, 'tr': 5}
id2lang = {}
for k, v in lang2id.items():
    id2lang[v] = k
# transformers.logging.set_verbosity_error()

# save model
def save_model(cfg, logger, step, model, optimizer, lr_scheduler):
    model_to_save = model.module if hasattr(model, 'module') else model
    # save static dict
    checkpoint = {
        'model': model_to_save.state_dict(),
        'optimizer': optimizer.state_dict(),
        'lr_scheduler': lr_scheduler.state_dict()
    }
    torch.save(checkpoint, get_ckpt_path(cfg).format(step))
    logger.info('save train model.')

# seeds
def set_seeds(SEED):
    np.random.seed(SEED)
    torch.manual_seed(SEED)

class ParallelCorpus(Data.Dataset):
    def __init__(self, data_path, cfg):
        self.data = self.process_data(data_path)
        self.tokenizer = XLMRobertaTokenizer.from_pretrained(cfg['model_name'])
        self.body_maxlen = cfg['body_maxlen']

    def process_data(self, data_paths):
        data = []
        for data_path in data_paths:
            with open(get_abs_path(data_path)) as f:
                for line in f.readlines():
                    data.append([line.split('\t')[0], int(line.split('\t')[1].strip()), lang2id[data_path[5:7]]])
            logger.info("Read {} pieces of samples".format(len(data)))
        return data

    def __len__(self):
        return len(self.data)

    def __getitem__(self, index):
        source = self.data[index][0]
        target = self.data[index][1]

        batch = self.tokenizer(source,
                             padding='max_length',
                             truncation=True,
                             max_length=self.body_maxlen,
                             return_tensors='pt')
        input_ids = batch['input_ids'].squeeze(0)

        return input_ids, torch.tensor(target, dtype=torch.long), torch.tensor(self.data[index][2], dtype=torch.int)


def train(model, optimizer, train_loader, dev_loader, epochs=1):
    logger.info('----Training----')

    # wandb
    if cfg['local_rank'] == 0:
        wandb.login(key='f841d6899cafcfbed913f5082886a4fe4af52c31')
        wandb.init(
            project=cfg['task']
        )
        wandb.watch(model, log='all', log_freq=100)

    # apex
    if USE_AMP:
        model, optimizer = amp.initialize(model, optimizer, opt_level='O1')

    # model
    if cfg['is_distributed']:
        model = torch.nn.parallel.DistributedDataParallel(
            model,
            device_ids=[cfg['local_rank']],
            output_device=cfg['local_rank']
        )

    local_batch_counts = cfg['epoch_num'] * int(len(train_loader))  # batch count in one GPU
    training_steps = int(np.ceil(local_batch_counts / cfg['accum_steps']))
    lr_scheduler = get_scheduler(
        "linear",
        optimizer=optimizer,
        num_warmup_steps=cfg['warmup_steps'],
        num_training_steps=training_steps
    )
    accum_steps = cfg['accum_steps']
    cur_step = 1
    for epoch in range(epochs):
        model.train()
        logger.info('Epoch {}'.format(epoch))
        for i, data in enumerate(tqdm(train_loader)):
            batch = tuple(t.to(device) for t in data)
            inputs = {"input_ids": batch[0], "labels": batch[1]}
            outputs = model(**inputs)
            loss = outputs[0]
            logger.info("step {}, training loss {}".format(i, loss.item()))
            loss = loss / accum_steps

            # apex
            if USE_AMP:
                with amp.scale_loss(loss, optimizer) as scaled_loss:
                    scaled_loss.backward()
            else:
                loss.backward()

            if (i + 1) % accum_steps == 0 or (i + 1) == int(len(train_loader)):
                optimizer.step()
                lr_scheduler.step()
                model.zero_grad()

                if ((i - 1 and i % cfg['eval_step'] == 1) or (i + 1) == int(len(train_loader))) and cfg['local_rank'] == 0:
                    dev_loss, dev_f1 = eval(cur_step, model, dev_loader, lr_scheduler)
                    metrics = dict()
                    metrics['train/loss'] = loss.item()
                    metrics['dev/loss'] = dev_loss
                    for k, v in dev_f1.items():
                        metrics[k] = v
                    wandb.log(metrics)

            if cfg['is_distributed']: torch.distributed.barrier()
            cur_step += 1
        # epoch end
        if epoch == epochs - 1:
            save_model(cfg, logger, cur_step, model, optimizer, lr_scheduler)

    if cfg['local_rank'] == 0:
        wandb.finish()


def get_metrics(preds, out_label_ids):
    preds = np.argmax(preds, axis=1)
    val_precision, val_recall, val_f1, _ = precision_recall_fscore_support(preds, out_label_ids, average='binary')
    val_acu = accuracy_score(preds, out_label_ids)
    return val_precision, val_recall, val_f1, val_acu


def eval(cur_step, model, val_dataloader, lr_scheduler=None):
    logger.info('Eval starts for current step {}'.format(cur_step))
    device = torch.device("cuda", cfg['local_rank']) if torch.cuda.is_available() else torch.device("cpu")
    model.to(device)
    model.eval()
    eval_loss, eval_steps, preds, out_label_ids = 0, 0, None, None
    preds_dict, out_label_ids_dict = defaultdict(list), defaultdict(list)
    with torch.no_grad():
        for idx, data in enumerate(tqdm(val_dataloader)):
            eval_steps += 1
            batch = tuple(t.to(device) for t in data)
            inputs = {"input_ids": batch[0], "labels": batch[1]}
            outputs = model(**inputs)
            loss, logits = outputs[:2]
            eval_loss += loss.item()
            logits_np, out_label_id_np, langs_np = logits.detach().cpu().numpy(), \
                                                   inputs["labels"].detach().cpu().numpy(), batch[2].detach().cpu().numpy()
            if preds is None:
                preds = logits_np
                out_label_ids = out_label_id_np
            else:
                preds = np.append(preds, logits_np, axis=0)
                out_label_ids = np.append(out_label_ids, out_label_id_np, axis=0)
            for i in range(len(langs_np)):
                preds_dict[langs_np[i]].append(logits_np[i])
                out_label_ids_dict[langs_np[i]].append(out_label_id_np[i])

    val_precision, val_recall, val_f1, val_acu = get_metrics(preds, out_label_ids)
    f1_dict = {}
    for lang, pred in preds_dict.items():
        precision, recall, f1, acu = get_metrics(pred, out_label_ids_dict[lang])
        f1_dict[id2lang[lang]+'/f1'] = f1
        f1_dict[id2lang[lang] + '/precision'] = precision
        f1_dict[id2lang[lang] + '/recall'] = recall
        f1_dict[id2lang[lang] + '/accuracy'] = acu

    f1_dict['all/f1'] = val_f1
    f1_dict['all/precision'] = val_precision
    f1_dict['all/recall'] = val_recall
    f1_dict['all/accuracy'] = val_acu
    if lr_scheduler and val_f1 < cfg['best_f1']:
        cfg['best_f1'] = val_f1
        logger.info('Congrats!')
        # ckpt_list.append(get_ckpt_path(cfg).format(cur_step))
        # if len(ckpt_list) > cfg['max_ckpt']:
        #     os.remove(ckpt_list.pop(0))
        # save_model(cfg, logger, cur_step, model, optimizer, lr_scheduler)

    model.train()
    logger.info('step {}, validation loss: {}, f1 score: {}'.format(cur_step, eval_loss / eval_steps, val_f1))
    logger.info('detail f1 score {}'.format(f1_dict))
    return eval_loss / eval_steps, f1_dict


def predict(model, pred_dataloader):
    device = torch.device("cuda", cfg['local_rank']) if torch.cuda.is_available() else torch.device("cpu")
    model.to(device)
    model.eval()
    preds, out_label_ids = None, None
    preds_dict, out_label_ids_dict = defaultdict(list), defaultdict(list)
    with torch.no_grad():
        for idx, data in enumerate(tqdm(pred_dataloader)):
            batch = tuple(t.to(device) for t in data)
            inputs = {"input_ids": batch[0], "labels": batch[1]}
            outputs = model(**inputs)
            loss, logits = outputs[:2]
            logits_np, out_label_id_np, langs_np = logits.detach().cpu().numpy(), \
                                                   inputs["labels"].detach().cpu().numpy(), batch[
                                                       2].detach().cpu().numpy()
            if preds is None:
                preds = logits_np
                out_label_ids = out_label_id_np
            else:
                preds = np.append(preds, logits_np, axis=0)
                out_label_ids = np.append(out_label_ids, out_label_id_np, axis=0)
            for i in range(len(langs_np)):
                preds_dict[langs_np[i]].append(logits_np[i])
                out_label_ids_dict[langs_np[i]].append(out_label_id_np[i])

        val_precision, val_recall, val_f1, val_acu = get_metrics(preds, out_label_ids)
        f1_dict = {}
        for lang, pred in preds_dict.items():
            precision, recall, f1, acu = get_metrics(pred, out_label_ids_dict[lang])
            f1_dict[id2lang[lang] + '/f1'] = f1
            f1_dict[id2lang[lang] + '/precision'] = precision
            f1_dict[id2lang[lang] + '/recall'] = recall
            f1_dict[id2lang[lang] + '/accuracy'] = acu

        f1_dict['all/f1'] = val_f1
        f1_dict['all/precision'] = val_precision
        f1_dict['all/recall'] = val_recall
        f1_dict['all/accuracy'] = val_acu
    logger.info("Corpus metrics score: {}".format(f1_dict))
    return preds, out_label_ids



if __name__ == '__main__':

    parser = argparse.ArgumentParser(description='News Headline Generation')
    parser.add_argument('-c', '--config', default='config.json', type=str, required=False,
                        help='config file path')
    parser.add_argument('-t', '--type', default='train', type=str, required=False, help='train / eval / predict')
    args, unknown = parser.parse_known_args()

    cfg = load_json(get_abs_path(args.config))
    cfg['time_str'] = args.type + '_' + get_datetime()
    set_seeds(cfg['seeds'])

    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    ckpt_list = []

    # gpu
    os.environ["CUDA_VISIBLE_DEVICES"] = cfg['gpu']
    cfg['is_distributed'] = len(cfg['gpu'].split(',')) > 1
    cfg['local_rank'] = 0

    # dpp
    if cfg['is_distributed'] and args.type == 'train':
        torch.distributed.init_process_group(backend="nccl", timeout=timedelta(hours=4))
        local_rank = torch.distributed.get_rank()
        torch.cuda.set_device(local_rank)
        cfg['local_rank'] = local_rank
        torch.cuda.synchronize()

    # logger
    logger = get_logger(cfg)
    logger.info(str(cfg))

    # model = MBart(freeze_bert=False, model_name=cfg['model_name'])
    model = BertForSequenceClassification.from_pretrained(cfg['model_name'], return_dict=True)
    optimizer = AdamW(model.parameters(), lr=cfg['lr'], weight_decay=cfg['weight_decay'])

    if os.path.exists(cfg['output_model']):
        logger.info('Loading model...')
        checkpoint = torch.load(cfg['output_model'], map_location='cpu')
        model.load_state_dict(checkpoint['model'])
        model.to(device)
        optimizer.load_state_dict(checkpoint['optimizer'])
    else:
        model.to(device)

    if args.type == 'train':
        # train_data = process_data(cfg['train_src_path'], cfg['train_tgt_path'])
        # dev_data = process_data(cfg['dev_src_path'], cfg['dev_tgt_path'])

        print('Reading training data...')
        train_set = ParallelCorpus(cfg['train_data_path'], cfg)
        train_loader = Data.DataLoader(train_set, batch_size=cfg['batch_size'], shuffle=True)

        print('Reading development data...')
        dev_set = ParallelCorpus(cfg['dev_data_path'], cfg)
        dev_loader = Data.DataLoader(dev_set, batch_size=cfg['batch_size'], shuffle=True)
        train(model, optimizer, train_loader, dev_loader, epochs=cfg['epoch_num'])
    elif args.type == 'eval':
        # dev_data = process_data(cfg['dev_src_path'], cfg['dev_tgt_path'])
        print('Reading development data...')
        dev_set = ParallelCorpus(cfg['dev_data_path'], cfg)
        dev_loader = Data.DataLoader(dev_set, batch_size=cfg['batch_size'], shuffle=True)
        eval(0, model, dev_loader)
    else:
        # test_data = process_data(cfg['test_src_path'], cfg['test_tgt_path'])
        print('Reading development data...')
        test_set = ParallelCorpus(cfg['test_data_path'], cfg)
        pred_loader = Data.DataLoader(test_set, batch_size=cfg['batch_size'], shuffle=True)
        predict(model, pred_loader)
